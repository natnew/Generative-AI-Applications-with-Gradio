{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## L1: NLP tasks with a simple interface"
      ],
      "metadata": {
        "id": "duFwCnwBY2g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotenv"
      ],
      "metadata": {
        "id": "asDu7dW7n5BC",
        "outputId": "eede6b3d-d2c1-476c-909c-117b0c23c9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KwIuCyqXdVd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "from IPython.display import Image, display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "hf_api_key = os.environ['HF_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "#Summarization endpoint\n",
        "def get_completion(inputs, parameters=None,ENDPOINT_URL=os.environ['HF_API_SUMMARY_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL, headers=headers,\n",
        "                                data=json.dumps(data)\n",
        "                               )\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "0KoMQlbYYnzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a text summarization app"
      ],
      "metadata": {
        "id": "IFLmpFnUYp5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are using an Inference Endpoint for the shleifer/distilbart-cnn-12-6, a 306M parameter distilled model from facebook/bart-large-cnn."
      ],
      "metadata": {
        "id": "0K6ETafBYtI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How about running it locally?\n",
        "The code would look very similar if you were running it locally instead of from an API. The same is true for all the models in the rest of the course, make sure to check the Pipelines documentation page\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "get_completion = pipeline(\"summarization\", model=\"shleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']"
      ],
      "metadata": {
        "id": "_BZ_Q0UJYt0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
        "        as an 81-storey building, and the tallest structure in Paris.\n",
        "        Its base is square, measuring 125 metres (410 ft) on each side.\n",
        "        During its construction, the Eiffel Tower surpassed the Washington\n",
        "        Monument to become the tallest man-made structure in the world,\n",
        "        a title it held for 41 years until the Chrysler Building\n",
        "        in New York City was finished in 1930. It was the first structure\n",
        "        to reach a height of 300 metres. Due to the addition of a broadcasting\n",
        "        aerial at the top of the tower in 1957, it is now taller than the\n",
        "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the\n",
        "        Eiffel Tower is the second tallest free-standing structure in France\n",
        "        after the Millau Viaduct.''')\n",
        "\n",
        "get_completion(text)"
      ],
      "metadata": {
        "id": "Vrwz2DzdYqwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting started with Gradio gr.Interface\n",
        "How about running it locally?\n",
        "The code would look very similar if you were running it locally. Simply remove all the paramters in the launch method\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "3OsbKFhtfpB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "Cl0oUEIYfqOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add demo.launch(share=True) to create a public link to share with your team or friends."
      ],
      "metadata": {
        "id": "H-kO8XFffvMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=summarize,\n",
        "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
        "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
        "                    title=\"Text summarization with distilbart-cnn\",\n",
        "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
        "                   )\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT2']))"
      ],
      "metadata": {
        "id": "BvCq96Onfvjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Named Entity Recognition app\n",
        "We are using this Inference Endpoint for dslim/bert-base-NER, a 108M parameter fine-tuned BART model on the NER task.\n",
        "\n",
        "#### How about running it locally?\n",
        "from transformers import pipeline\n",
        "\n",
        "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "\n",
        "def ner(input):\n",
        "    output = get_completion(input)\n",
        "    return {\"text\": input, \"entities\": output}"
      ],
      "metadata": {
        "id": "DXEhxuNjfxYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = os.environ['HF_API_NER_BASE'] #NER endpoint\n",
        "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
        "get_completion(text, parameters=None, ENDPOINT_URL= API_URL)"
      ],
      "metadata": {
        "id": "gxQfbSWkf02X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner(input):\n",
        "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    return {\"text\": input, \"entities\": output}\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=ner,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "                    title=\"NER with dslim/bert-base-NER\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
        "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT3']))"
      ],
      "metadata": {
        "id": "RsMGgZ1df2hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding a helper function to merge tokens"
      ],
      "metadata": {
        "id": "XrR1CVpRf4C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_tokens(tokens):\n",
        "    merged_tokens = []\n",
        "    for token in tokens:\n",
        "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
        "            # If current token continues the entity of the last one, merge them\n",
        "            last_token = merged_tokens[-1]\n",
        "            last_token['word'] += token['word'].replace('##', '')\n",
        "            last_token['end'] = token['end']\n",
        "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
        "        else:\n",
        "            # Otherwise, add the token to the list\n",
        "            merged_tokens.append(token)\n",
        "\n",
        "    return merged_tokens\n",
        "\n",
        "def ner(input):\n",
        "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    merged_tokens = merge_tokens(output)\n",
        "    return {\"text\": input, \"entities\": merged_tokens}\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=ner,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "                    title=\"NER with dslim/bert-base-NER\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT4']))"
      ],
      "metadata": {
        "id": "zshoOrByf5qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()"
      ],
      "metadata": {
        "id": "KeveZ1_Vf-BW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}