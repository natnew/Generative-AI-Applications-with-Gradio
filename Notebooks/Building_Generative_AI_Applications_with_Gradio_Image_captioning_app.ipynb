{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##L2: Image captioning app"
      ],
      "metadata": {
        "id": "ebt9Mskv0V67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "hf_api_key = os.environ['HF_API_KEY']"
      ],
      "metadata": {
        "id": "-ik_UUVV0WaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "import requests, json\n",
        "\n",
        "#Image-to-text endpoint\n",
        "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "44doTzOY0Zhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an image captioning app\n",
        "Here we'll be using an Inference Endpoint for Salesforce/blip-image-captioning-base a 14M parameter captioning model.\n",
        "\n",
        "The code would look very similar if you were running it locally instead of from an API. You can check the Pipelines documentation page.\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "get_completion = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['generated_text']\n",
        "The free images are available on: https://free-images.com/"
      ],
      "metadata": {
        "id": "zrYtVSfX0cKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n",
        "display(IPython.display.Image(url=image_url))\n",
        "get_completion(image_url)"
      ],
      "metadata": {
        "id": "UulzNbaW0e91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Captioning with gr.Interface()"
      ],
      "metadata": {
        "id": "xv9Ge3tL0iz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def image_to_base64_str(pil_image):\n",
        "    byte_arr = io.BytesIO()\n",
        "    pil_image.save(byte_arr, format='PNG')\n",
        "    byte_arr = byte_arr.getvalue()\n",
        "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def captioner(image):\n",
        "    base64_image = image_to_base64_str(image)\n",
        "    result = get_completion(base64_image)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=captioner,\n",
        "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
        "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
        "                    title=\"Image Captioning with BLIP\",\n",
        "                    description=\"Caption any image using the BLIP model\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"])\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "eBLVN2xj0jmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()"
      ],
      "metadata": {
        "id": "9RseeBtb0m8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TW3d7K5W0n3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}