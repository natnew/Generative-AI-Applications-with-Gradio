{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## L3: Image generation app"
      ],
      "metadata": {
        "id": "dHilvC9m00B7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "hf_api_key = os.environ['HF_API_KEY']"
      ],
      "metadata": {
        "id": "FUKJtAor00zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "#Text-to-image endpoint\n",
        "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "nu0Ez1zA04Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an image generation app\n",
        "Here we are going to run runwayml/stable-diffusion-v1-5 using the ðŸ§¨ diffusers library.\n",
        "\n",
        "#### How about running it locally?\n",
        "The code would look very similar if you were running it locally instead of from an API.\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "\n",
        "def get_completion(prompt):\n",
        "    return pipeline(prompt).images[0]  "
      ],
      "metadata": {
        "id": "C1KtUqG_05-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a dog in a park\"\n",
        "\n",
        "result = get_completion(prompt)\n",
        "IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"
      ],
      "metadata": {
        "id": "R3pRoXcL09QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating with gr.Interface()"
      ],
      "metadata": {
        "id": "Kq2eoI8T0_B7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "#A helper function to convert the PIL image to base64\n",
        "#so you can send it to the API\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def generate(prompt):\n",
        "    output = get_completion(prompt)\n",
        "    result_image = base64_to_pil(output)\n",
        "    return result_image\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate,\n",
        "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "XXbaahGL1BiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "oElKL9wu1DjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a more advanced interface"
      ],
      "metadata": {
        "id": "CskpI8sg1FDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "#A helper function to convert the PIL image to base64\n",
        "# so you can send it to the API\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
        "    params = {\n",
        "        \"negative_prompt\": negative_prompt,\n",
        "        \"num_inference_steps\": steps,\n",
        "        \"guidance_scale\": guidance,\n",
        "        \"width\": width,\n",
        "        \"height\": height\n",
        "    }\n",
        "\n",
        "    output = get_completion(prompt, params)\n",
        "    pil_image = base64_to_pil(output)\n",
        "    return pil_image\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate,\n",
        "                    inputs=[\n",
        "                        gr.Textbox(label=\"Your prompt\"),\n",
        "                        gr.Textbox(label=\"Negative prompt\"),\n",
        "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
        "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                                  info=\"Controls how much the text prompt influences the result\"),\n",
        "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
        "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
        "                    ],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\"\n",
        "                    )\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT2']))"
      ],
      "metadata": {
        "id": "KupeXHlv1Hpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "aHQUHz7u1KVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gr.Blocks() to the rescue!"
      ],
      "metadata": {
        "id": "BRM6NqjD1Mm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    prompt = gr.Textbox(label=\"Your prompt\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "            btn = gr.Button(\"Submit\")\n",
        "        with gr.Column():\n",
        "            output = gr.Image(label=\"Result\")\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT3']))"
      ],
      "metadata": {
        "id": "1ZrvoFKq1Or6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=4):\n",
        "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
        "        with gr.Column(scale=1, min_width=50):\n",
        "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
        "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "                with gr.Column():\n",
        "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "    output = gr.Image(label=\"Result\") #Move the output up too\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT4']))"
      ],
      "metadata": {
        "id": "ZfWnWqOb1Rjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()"
      ],
      "metadata": {
        "id": "oVrxl-rq1TsD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}